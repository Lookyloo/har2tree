{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Har2Tree Tutorial\n",
    "\n",
    "Crawling a web page can sound like a bit of an abstract concept at first. How exactly can we extract data from a web page? What data is really interesting to look at? Where can it be found?  \n",
    "\n",
    "&rarr; Every web browser generates a **[HAR file](https://www.keycdn.com/support/what-is-a-har-file#:~:text=HAR%2C%20short%20for%20HTTP%20Archive,times%2C%20and%20page%20rendering%20problems.)** (short for http archive) when loading a web page. This file mostly contains information about what resources are loaded by the browser, as it was firstly designed to identify possible performance issues. However, as the whole file is in a *standard JSON* format, **we can reverse engineer the process to extract useful information** and make a whole tree out of all the resources found in that HAR file. This step is particularly important as it is really complicated to understand what is going on by simply looking at the HAR file. *Example [here](https://gist.githubusercontent.com/Felalex57/8a90a3bd0628e3aef16ee04fb08e7e7e/raw/ecee33d26c5696989c600ba87683becff270ccc1/example.har)!*\n",
    "\n",
    "This notebook will guide you through the core features that **[Har2Tree](https://github.com/Lookyloo/har2tree)** offers.\n",
    "\n",
    "It is also important to note that Har2Tree is an API based on the **[TreeNode](http://etetoolkit.org/docs/latest/reference/reference_tree.html) class of ETE3 Toolkit** and that a lot of help can be found on the documentation there in case you want to know a bit more about how the program works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we do anything: Setup\n",
    "\n",
    "## 1. Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following tutorial, we assume you have the following environment at your disposal.\n",
    "\n",
    "1. Ubuntu 20.04 or more recent. You can also work with WSL 2 \n",
    "\n",
    "\n",
    "2. Python 3.8 or 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installing har2tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are here it means that you already cloned the har2tree repository:  **you should be all set up already**!\n",
    "\n",
    "In case you got here another way, simply clone the repository in your desired folder:  \n",
    "```bash\n",
    "git clone https://github.com/Lookyloo/har2tree.git\n",
    "```\n",
    "\n",
    "You may also want to initialize a submodule containing a few sample captures:\n",
    "\n",
    "``` bash\n",
    "git submodule update --init --recursive\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 3. Retrieving useful files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you could use a pre-existing capture made for the tests of har2tree. They are located in **`tests / capture_samples`**.\n",
    "However, you might want to take a look at how the files are downloaded **to have a better understanding of the program** and eventually use it on some pages of your choice.\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Important note:** Because Har2Tree was made for Lookyloo, it may require some additional files located in the same folder as the HAR file to be completely operational. To ensure that the program will fully work, we will simulate a capture using the **[public Lookyloo instance](https://lookyloo.circl.lu/)** rather than download the HAR file in the conventional way *(on Chrome: Ctrl + Shift + J > Network > F5 (Reload the page) > Arrow facing downwards)* . \n",
    "\n",
    "\n",
    "\n",
    "By simply **adding `/export` at the end of the url** when browsing on a capture, we can **download all the files generated by Lookyloo**. This includes the complete html capture of the page along with various other files that we will get into later on.\n",
    "\n",
    " \n",
    "Capture link: &nbsp;&nbsp; &rarr;  https://lookyloo.circl.lu/tree/b6b29698-4c97-4a21-adaa-f934e5bfb042  \n",
    "Download link: &rarr; https://lookyloo.circl.lu/tree/b6b29698-4c97-4a21-adaa-f934e5bfb042/export\n",
    "\n",
    "You can then unzip the folder in the desired folder of your choice and your HAR folder is now ready!  \n",
    "**Tip:** unzip the folder in the same directory as this notebook, it will be easier for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The place where the magic of the API begins is the **[CrawledTree object](https://github.com/Lookyloo/har2tree/blob/9f92dab3909e406877cb36b3dbc30d0c5ead8c63/har2tree/parser.py#L15) :**  it takes a list of **HAR file paths** and a  **[uuid](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20UUID,%2C%20for%20practical%20purposes%2C%20unique.)** as parameters. <br/> To keep things simple for now, we will only be using **one HAR file per tree**.\n",
    "To build OS paths in python, we are going to use the **Path** class from **pathlib**.  \n",
    "\n",
    "Note that the keyword `__file__` doesn't work on Jupyter.  \n",
    "\n",
    "Let's see how we can tell the program to display our home directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path.home()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now let's try to create our first tree. As mentioned before, you will also need to pass a uuid as a parameter, but don't worry, python has everything you need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little notes though:\n",
    "- *CrawledTree* takes a string as parameter and not a UUID, we just have to make a little conversion\n",
    "- it takes a list of HAR paths, even if there's only one path as mentioned before\n",
    "\n",
    "You might want to change the HAR path to what you downloaded in part 3 of the setup.\n",
    "Enough talking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from har2tree import CrawledTree\n",
    "har_path = Path() / '..' / 'tests' / 'capture_samples' / 'http_redirect' / '0.har'\n",
    "my_first_crawled_tree = CrawledTree([har_path], str(uuid.uuid4()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Extracting simple data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you didnt get an error, everything worked! Let's now see what we can do with that CrawledTree. \n",
    "You can find all the **properties** in the **[parser.py](https://github.com/Lookyloo/har2tree/blob/9f92dab3909e406877cb36b3dbc30d0c5ead8c63/har2tree/parser.py#L76)** file.\n",
    "\n",
    "First, let's see what website you got the capture from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_crawled_tree.root_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not also check at what time the capture was made, as well as the **[user agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent)** that made it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_first_crawled_tree.start_time)\n",
    "print(my_first_crawled_tree.user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, what really interests us: **let's see if there are any [redirects](https://moz.com/learn/seo/redirection) on the page**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_first_crawled_tree.redirects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it for the first part. With very few lines of codes, we are able to extract very useful information in neglectable execution time. This makes it so much easier than having to go through the HAR file and find what you're looking for.\n",
    "\n",
    "In the second part, we'll dig into the more complex features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: the second level\n",
    "\n",
    "In this part we will look into the root_hartree property of CrawledTree, which is nothing else than a Har2Tree object inside CrawledTree. You can see that it is **initialized [here](https://github.com/Lookyloo/har2tree/blob/f908280347b4b33f8ef0dd750d372dcd825634ed/har2tree/parser.py#L25)**.  \n",
    "\n",
    "The few properties we saw before are here to simplify the access of that sub-level tree. They are called **[that way](https://github.com/Lookyloo/har2tree/blob/f908280347b4b33f8ef0dd750d372dcd825634ed/har2tree/parser.py#L79)** : `CrawledTree.root_hartree.method`\n",
    "\n",
    "### Har2Tree properties\n",
    "\n",
    "Let's start with something simple and display the start time to check if we get the same result as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_first_crawled_tree.root_hartree.start_time)\n",
    "print(my_first_crawled_tree.root_hartree.start_time == my_first_crawled_tree.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats property calls multiple useful other properties and displays them nicely in a JSON format. You can find what it calls **[here](https://github.com/Lookyloo/har2tree/blob/f908280347b4b33f8ef0dd750d372dcd825634ed/har2tree/har2tree.py#L370)** and trace it back to the other properties in case you want to know something in specific that is not covered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_crawled_tree.root_hartree.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very interesting property to look at is `root_after_redirect`: it returns a URL in case there is at least one redirect on the capture. \n",
    "The returned URL is the URL that you'll end up with after following all redirects of the page. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_crawled_tree.root_hartree.root_after_redirect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at **[the code](https://github.com/Lookyloo/har2tree/blob/66817c2c56697fd9a6ff3e42820978802e84faa0/har2tree/har2tree.py#L480)**, you'll notice that we actually call the function from **`har`** which is nothing else than **[an instance of HarFile](https://github.com/Lookyloo/har2tree/blob/66817c2c56697fd9a6ff3e42820978802e84faa0/har2tree/har2tree.py#L259)** to make it clearer inside of the Har2Tree class. You can find its definition in **[the same file](https://github.com/Lookyloo/har2tree/blob/66817c2c56697fd9a6ff3e42820978802e84faa0/har2tree/har2tree.py#L251)** as its main use is to pre-process a lot of data useful in the Har2Tree class.\n",
    "\n",
    "Let's see some of its interesting features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_properties = my_first_crawled_tree.root_hartree.har    # For more readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('uuid: ' + har_properties.capture_uuid)   \n",
    "print('Path: ' + str(har_properties.path) + '\\n')    # What we defined before\n",
    "\n",
    "print('Initial redirects: ' + str(har_properties.has_initial_redirects))  # Our example from before \n",
    "print('Final redirect: ' + har_properties.final_redirect + '\\n')    # Same as root_after_redirect\n",
    "\n",
    "print('Unique representation: ' + repr(har_properties))   # path of the capture and the uuid at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only execute that one if you want to see all the informations of one given URL.\n",
    "You could also remove the [0] to print out all entries but it takes <span style=\"color:red\">a lot of time</span> and it is enough to print just the first one to get a good idea of what an entry looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(har_properties.entries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the URL is located in `request > url`. Let's see what we can do with that.\n",
    "\n",
    "\n",
    "This next example is quite interesting. It shows the number of entries in the capture; then it prints out all the URLs loaded by the page; you can even retrace the redirects in the first 4 URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in har_properties.entries:\n",
    "    print(entry['request']['url'])\n",
    "print(har_properties.number_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Note:</span> and of course this is also implemented in the all_url_requests attribute, but in the Har2Tree class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_first_crawled_tree.root_hartree.all_url_requests)\n",
    "print(len(my_first_crawled_tree.root_hartree.all_url_requests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can however see that we only have 6 as the duplicates were removed compared to 7 before.\n",
    "And that weird Tree Node thing... we're getting there in the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nodes.py\n",
    "As you can see [in this file](https://github.com/Lookyloo/har2tree/blob/66817c2c56697fd9a6ff3e42820978802e84faa0/har2tree/nodes.py), the nodes we use come from the [Ete3 toolkit API](http://etetoolkit.org/docs/latest/reference/reference_tree.html). \n",
    "\n",
    "Let's try to see what one of those nodes looks like; we'll begin with URLNode as it's pretty self explanatory.\n",
    "\n",
    "We are going to use the [rendered_node] property as it returns the node which will ultimately be displayed on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_first_crawled_tree.root_hartree.rendered_node)\n",
    "print(\"\\n\")\n",
    "print(my_first_crawled_tree.root_hartree.rendered_node.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might find weird that *<span style=\"color:#8b8b8b\">the rendered URL itself is not displayed</span>*. It's because the name of the node itself is not returned in the `__str__` [method](https://github.com/etetoolkit/ete/blob/1f587a315f3c61140e3bdbe697e3e86eda6d2eca/ete3/coretype/tree.py#L251) of the TreeNode class as the show_internal parameter is [set to False](https://github.com/etetoolkit/ete/blob/1f587a315f3c61140e3bdbe697e3e86eda6d2eca/ete3/coretype/tree.py#L67) by default.\n",
    "\n",
    "- You could simply print out the name of the node like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_crawled_tree.root_hartree.rendered_node.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Or you could invoke the get_ascii method because its default show_internal parameter [is set to True](https://github.com/etetoolkit/ete/blob/1f587a315f3c61140e3bdbe697e3e86eda6d2eca/ete3/coretype/tree.py#L1491) but you will have to zoom out to get someting readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_first_crawled_tree.root_hartree.rendered_node.get_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, you could run this little script. It invokes the method .show() of a node which opens a window with an interactive interface and really helps visualizing what the node actually contains. However, you may face a lot of problems while running it, so [here is a screenshot](https://postimg.cc/4Y40H99m) just in case.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **<span style=\"color:blue\">Note:</span>** you might want to take a look [here](https://itsfoss.com/unable-to-locate-package-error-ubuntu/) and [there](https://gist.github.com/davydka/6715e74bd67501ee0a98e40b9820857c), it really helped me to fix bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: I didnt manage to fix that one...\n",
    "from getpass import getpass\n",
    "!echo {getpass()} | \"sudo -S ./interactive_tree.sh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another interesting property that lists what URLs the elements that have href attribute lead to (it's way easier than it sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_crawled_tree.root_hartree.rendered_node.urls_in_rendered_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for something a bit more complicated: let's try to find the node containing the root URL using a method we saw previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_crawled_tree.root_hartree.url_tree.search_nodes(name=my_first_crawled_tree.root_url)[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
